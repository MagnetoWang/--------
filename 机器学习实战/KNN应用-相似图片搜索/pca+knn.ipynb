{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import numbers\n",
    "from scipy.sparse.linalg import svds\n",
    "import warnings\n",
    "\n",
    "\n",
    "class PCA:\n",
    "\n",
    "    def __init__(self, n_components=None,svd_solver='auto'):\n",
    "        # assert n_components >= 1, \"n_components must be valid\"\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.n_components_ = None\n",
    "        self.svd_solver = svd_solver\n",
    "\n",
    "    def svd_flip(self,u,v,u_based_decision=True):\n",
    "        if u_based_decision:\n",
    "            # columns of u, rows of v\n",
    "            max_abs_cols = np.argmax(np.abs(u), axis=0)\n",
    "            signs = np.sign(u[max_abs_cols, range(u.shape[1])])\n",
    "            u *= signs\n",
    "            v *= signs[:, np.newaxis]\n",
    "        else:\n",
    "            # rows of v, columns of u\n",
    "            max_abs_rows = np.argmax(np.abs(v), axis=1)\n",
    "            signs = np.sign(v[range(v.shape[0]), max_abs_rows])\n",
    "            u *= signs\n",
    "            v *= signs[:, np.newaxis]\n",
    "        return u, v\n",
    "\n",
    "    def stable_cumsum(self,arr,axis=None,rtol=1e-05,atol=1e-8):\n",
    "        # if np_version < (1, 9):\n",
    "        #     return np.cumsum(arr, axis=axis, dtype=np.float64)\n",
    "\n",
    "        out = np.cumsum(arr, axis=axis, dtype=np.float64)\n",
    "        expected = np.sum(arr, axis=axis, dtype=np.float64)\n",
    "        if not np.all(np.isclose(out.take(-1, axis=axis), expected, rtol=rtol,\n",
    "                                 atol=atol, equal_nan=True)):\n",
    "            warnings.warn('cumsum was found to be unstable: '\n",
    "                          'its last element does not correspond to sum',\n",
    "                          RuntimeWarning)\n",
    "        return out\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "\n",
    "        self._fit(X)\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "\n",
    "        U, S, V = self._fit(X)\n",
    "        U = U[:,:self.n_components_]\n",
    "\n",
    "        return U\n",
    "\n",
    "    def _fit(self,X):\n",
    "        if self.n_components is None:\n",
    "            if self.svd_solver != 'arpack':\n",
    "                n_components = min(X.shape)\n",
    "            else:\n",
    "                n_components = min(X.shape) - 1\n",
    "        else:\n",
    "            n_components = self.n_components\n",
    "\n",
    "        svd_solver = self.svd_solver\n",
    "\n",
    "        if svd_solver == 'auto':\n",
    "            # Small problem or n_components == 'mle', just call full PCA\n",
    "            if max(X.shape) <= 500 :\n",
    "                svd_solver = 'full'\n",
    "            elif n_components >= 1 and n_components < .8 * min(X.shape):\n",
    "                svd_solver = 'randomized'\n",
    "            # This is also the case of n_components in (0,1)\n",
    "            else:\n",
    "                svd_solver = 'full'\n",
    "\n",
    "        # Call different fits for either full or truncated SVD\n",
    "        if svd_solver == 'full':\n",
    "            return self._fit_full(X, n_components)\n",
    "        elif svd_solver in ['arpack', 'randomized']:\n",
    "            return self._fit_truncated(X, n_components, svd_solver)\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
    "                             \"\".format(svd_solver))\n",
    "\n",
    "    def _fit_full(self,X,n_components):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "\n",
    "        if not 0 <= n_components <= min(n_samples, n_features):\n",
    "            raise ValueError(\"n_components=%r must be between 0 and \"\n",
    "                             \"min(n_samples, n_features)=%r with \"\n",
    "                             \"svd_solver='full'\"\n",
    "                             % (n_components, min(n_samples, n_features)))\n",
    "        elif n_components >= 1:\n",
    "            if not isinstance(n_components, (numbers.Integral, np.integer)):\n",
    "                raise ValueError(\"n_components=%r must be of type int \"\n",
    "                                 \"when greater than or equal to 1, \"\n",
    "                                 \"was of type=%r\"\n",
    "                                 % (n_components, type(n_components)))\n",
    "\n",
    "        self.mean_ = np.mean(X,axis=0)\n",
    "        X_demean = X - self.mean_\n",
    "\n",
    "        U,S,V = np.linalg.svd(X_demean, full_matrices=False)\n",
    "#         U,V = self.svd_flip(U,V)\n",
    "\n",
    "        components_ = V\n",
    "\n",
    "        explained_variance_ = (S**2)/(n_samples-1)\n",
    "        total_var = explained_variance_.sum()\n",
    "        explained_variance_ratio_ = explained_variance_/total_var\n",
    "        singular_values_ = S.copy()\n",
    "\n",
    "        if 0 < n_components < 1.0:\n",
    "            # number of components for which the cumulated explained\n",
    "            # variance percentage is superior to the desired threshold\n",
    "            ratio_cumsum = self.stable_cumsum(explained_variance_ratio_)\n",
    "            n_components = np.searchsorted(ratio_cumsum, n_components) + 1\n",
    "\n",
    "            # Compute noise covariance using Probabilistic PCA model\n",
    "            # The sigma2 maximum likelihood (cf. eq. 12.46)\n",
    "        if n_components < min(n_features, n_samples):\n",
    "            self.noise_variance_ = explained_variance_[n_components:].mean()\n",
    "        else:\n",
    "            self.noise_variance_ = 0.\n",
    "\n",
    "        self.n_samples_, self.n_features_ = n_samples, n_features\n",
    "        self.components_ = components_[:n_components]\n",
    "        self.n_components_ = n_components\n",
    "        self.explained_variance_ = explained_variance_[:n_components]\n",
    "        self.explained_variance_ratio_ = \\\n",
    "            explained_variance_ratio_[:n_components]\n",
    "        self.singular_values_ = singular_values_[:n_components]\n",
    "\n",
    "        return U, S, V\n",
    "\n",
    "    def _fit_truncated(self,X,n_components,svd_solver):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        X_demean = X - self.mean_\n",
    "\n",
    "#         if svd_solver == 'arpack':\n",
    "            # random init solution, as ARPACK does it internally\n",
    "        v0 = np.random.uniform(-1, 1, size=min(X_demean.shape))\n",
    "        U, S, V = svds(X_demean, k=n_components, tol=0.0, v0=v0)\n",
    "            # svds doesn't abide by scipy.linalg.svd/randomized_svd\n",
    "            # conventions, so reverse its outputs.\n",
    "        S = S[::-1]\n",
    "            # flip eigenvectors' sign to enforce deterministic output\n",
    "#             U, V = self.svd_flip(U[:, ::-1], V[::-1])\n",
    "\n",
    "        self.n_samples_, self.n_features_ = n_samples, n_features\n",
    "        self.components_ = V\n",
    "        self.n_components_ = n_components\n",
    "\n",
    "        # Get variance explained by singular values\n",
    "        self.explained_variance_ = (S ** 2) / (n_samples - 1)\n",
    "        total_var = np.var(X_demean, ddof=1, axis=0)\n",
    "        self.explained_variance_ratio_ = \\\n",
    "            self.explained_variance_ / total_var.sum()\n",
    "        self.singular_values_ = S.copy()  # Store the singular values.\n",
    "\n",
    "        if self.n_components_ < min(n_features, n_samples):\n",
    "            self.noise_variance_ = (total_var.sum() -\n",
    "                                    self.explained_variance_.sum())\n",
    "            self.noise_variance_ /= min(n_features, n_samples) - n_components\n",
    "        else:\n",
    "            self.noise_variance_ = 0.\n",
    "\n",
    "        return U, S, V\n",
    "\n",
    "    def transform(self,X):\n",
    "        if self.mean_ is not None:\n",
    "            X_demean = X - self.mean_\n",
    "        X_transformed = np.dot(X_demean, self.components_.T)\n",
    "        return X_transformed\n",
    "\n",
    "    def inverse_transform(self,X):\n",
    "        return np.dot(X,self.components_)+self.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n",
      "Wall time: 4.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from PIL import Image\n",
    "data1 = []\n",
    "for j in range(0, 10):\n",
    "    for i in range(0,100):\n",
    "        im = Image.open('C:\\\\Users\\\\Magneto_Wang\\\\Documents\\\\GitHub\\\\机器学习个人笔记\\\\机器学习实战\\\\PCA算法实现\\\\灰度图片\\\\%s.jpg' %(100*j+i) )\n",
    "        mtr = np.array(im)\n",
    "#         if mtr.shape[0] < mtr.shape[1]:\n",
    "#             mtr = mtr.T\n",
    "#         print(mtr.shape)\n",
    "        \n",
    "        s = mtr.reshape(1, 98304)\n",
    "        data1.append(s)\n",
    "     #   print(s.shape)\n",
    "    \n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1, 98304)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_np = np.array(data1, dtype=int)\n",
    "data1_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 98304)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_np=data1_np.reshape((1000,98304))\n",
    "data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pca = PCA(80)\n",
    "pca.fit(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 80)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reduction = pca.transform(data_np)\n",
    "data_reduction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "def knn(X,k,number):\n",
    "    distances = [sqrt(np.sum((x - X[number])**2)) for x in X]\n",
    "    nearest = np.argsort(distances)\n",
    "    return nearest[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knnn = knn(data_reduction, 8, 729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([729, 773, 797, 772, 186, 749, 978, 697], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import *\n",
    "import numpy as np\n",
    "def knn(X,y,k,number):\n",
    "    distances = [sqrt(np.sum((x - X[number])**2)) for x in X]\n",
    "    nearest = np.argsort(distances)\n",
    "    topK_y = [y[i] for i in nearest[1:k]]\n",
    "    votes = Counter(topK_y)\n",
    "    \n",
    "    return nearest[1:k],votes.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = np.zeros(100,dtype=np.uint8)\n",
    "y1 = np.ones(100,dtype=np.uint8)\n",
    "y2 = y1+1\n",
    "y3 = y2+1\n",
    "y4 = y3+1\n",
    "y5 = y4+1\n",
    "y6 = y5+1\n",
    "y7 = y6+1\n",
    "y8 = y7+1\n",
    "y9 = y8+1\n",
    "y = np.concatenate((y0, y1,y2,y3,y4,y5,y6,y7,y8,y9),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "near,predict_y = knn(data_reduction,y,8,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([147, 795, 819, 785, 718, 151, 214], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y\n",
    "near"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run knn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf=KNNClassifier(k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNN(K=6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(data_reduction, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_predict = np.array([23,45,123,234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict = knn_clf.predict(729)\n",
    "# print(y_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 80)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reduction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_indexes = np.random.permutation(len(data_reduction))\n",
    "# shuffle_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = int(len(data_reduction) * test_ratio)\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indexes = shuffle_indexes[:test_size]\n",
    "train_indexes = shuffle_indexes[test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_reduction[train_indexes]\n",
    "y_train = y[train_indexes]\n",
    "\n",
    "X_test = data_reduction[test_indexes]\n",
    "y_test = y[test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 80)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_knn = KNNClassifier(k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNN(K=6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = my_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 5, 1, 5, 5, 7, 8, 7, 7, 5, 7, 7, 8, 7, 5, 1, 8, 7, 6, 7, 1, 3,\n",
       "       7, 4, 8, 9, 7, 1, 6, 6, 8, 5, 1, 1, 9, 4, 5, 6, 6, 1, 7, 7, 7, 4, 4,\n",
       "       6, 6, 5, 7, 7, 2, 6, 5, 6, 1, 4, 7, 7, 7, 7, 6, 1, 1, 4, 7, 7, 7, 7,\n",
       "       7, 7, 1, 6, 8, 6, 4, 6, 7, 7, 7, 6, 6, 1, 6, 7, 7, 1, 7, 3, 6, 7, 1,\n",
       "       7, 1, 7, 7, 8, 8, 9, 6, 2, 8, 7, 2, 4, 4, 1, 7, 1, 8, 7, 6, 3, 4, 7,\n",
       "       7, 6, 7, 7, 8, 1, 8, 8, 7, 7, 1, 7, 7, 8, 6, 1, 1, 7, 1, 5, 4, 6, 7,\n",
       "       7, 4, 1, 6, 6, 6, 1, 1, 1, 5, 4, 6, 8, 3, 5, 1, 8, 8, 4, 4, 7, 6, 5,\n",
       "       7, 1, 5, 7, 4, 7, 8, 5, 8, 7, 6, 7, 7, 7, 7, 8, 1, 7, 8, 7, 4, 8, 6,\n",
       "       7, 6, 1, 8, 7, 1, 5, 7, 2, 5, 6, 5, 7, 4, 4, 7], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.435"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_predict == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.46\n",
      "4 0.465\n",
      "5 0.45\n",
      "6 0.435\n",
      "7 0.425\n",
      "8 0.455\n",
      "9 0.445\n",
      "10 0.45\n",
      "11 0.455\n",
      "12 0.455\n",
      "13 0.44\n",
      "14 0.435\n",
      "15 0.43\n",
      "16 0.43\n",
      "17 0.43\n",
      "18 0.425\n",
      "19 0.44\n",
      "20 0.45\n",
      "21 0.445\n",
      "22 0.44\n",
      "23 0.43\n",
      "24 0.435\n",
      "25 0.43\n",
      "26 0.43\n",
      "27 0.425\n",
      "28 0.43\n",
      "29 0.43\n",
      "30 0.43\n",
      "31 0.43\n",
      "32 0.425\n",
      "33 0.435\n",
      "34 0.43\n",
      "35 0.44\n",
      "36 0.44\n",
      "37 0.44\n",
      "38 0.43\n",
      "39 0.43\n",
      "40 0.43\n",
      "41 0.43\n",
      "42 0.425\n",
      "43 0.425\n",
      "44 0.42\n",
      "45 0.42\n",
      "46 0.41\n",
      "47 0.405\n",
      "48 0.41\n",
      "49 0.405\n"
     ]
    }
   ],
   "source": [
    "for k in range(3,50):\n",
    "    my_knn = KNNClassifier(k)\n",
    "    my_knn.fit(X_train, y_train)\n",
    "    y_predict = my_knn.predict(X_test)\n",
    "    print(k, sum(y_predict == y_test)/len(y_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
