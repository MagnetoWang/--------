{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n朴素贝叶斯算法\\n【朴素：特征条件独立   贝叶斯：基于贝叶斯定理】\\n\\n1朴素贝叶斯的概念【联合概率分布、先验概率、条件概率**、全概率公式】【条件独立性假设、】   极大似然估计\\n\\n2优缺点    \\n【优点： 分类效率稳定；对缺失数据不敏感，算法比较简单，常用于文本分类；在属性相关性较小时，该算法性能最好    缺点：假设属性之间相互独立；先验概率多取决于假设；对输入数据的表达形式很敏感】\\n\\n3先验概率、后验概率\\n先验概率的计算比较简单，没有使用贝叶斯公式；\\n而后验概率的计算，要使用贝叶斯公式，而且在利用样本资料计算逻辑概率时，还要使用理论概率分布，需要更多的数理统计知识。\\n\\n4朴素贝叶斯的参数估计：\\n①极大似然估计（可能出现概率为0的情况）②贝叶斯估计（加入常数，拉普拉斯平滑）\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "朴素贝叶斯算法\n",
    "【朴素：特征条件独立   贝叶斯：基于贝叶斯定理】\n",
    "\n",
    "1朴素贝叶斯的概念【联合概率分布、先验概率、条件概率**、全概率公式】【条件独立性假设、】   极大似然估计\n",
    "\n",
    "2优缺点    \n",
    "【优点： 分类效率稳定；对缺失数据不敏感，算法比较简单，常用于文本分类；在属性相关性较小时，该算法性能最好    缺点：假设属性之间相互独立；先验概率多取决于假设；对输入数据的表达形式很敏感】\n",
    "\n",
    "3先验概率、后验概率\n",
    "先验概率的计算比较简单，没有使用贝叶斯公式；\n",
    "而后验概率的计算，要使用贝叶斯公式，而且在利用样本资料计算逻辑概率时，还要使用理论概率分布，需要更多的数理统计知识。\n",
    "\n",
    "4朴素贝叶斯的参数估计：\n",
    "①极大似然估计（可能出现概率为0的情况）②贝叶斯估计（加入常数，拉普拉斯平滑）\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*-1\n",
      "S*-1\n",
      "2*1\n",
      "S*1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8afe897dc359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'S'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;31m#该特征应属于哪一类\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'属于'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-8afe897dc359>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(self, trainData, labels, features)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mClass_each\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprobability_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Class_each[y]\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mClass_each\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0mClass_each\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mClass_each\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not float"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Latex\n",
    "\n",
    "\n",
    "\n",
    "class NaiveBayes(object):\n",
    "    #返回数据表和标签\n",
    "    def getTrainSet(self):\n",
    "        \n",
    "        \n",
    "        dataSet = pd.read_csv('naivebayes_data.csv')\n",
    "        dataSetNP = np.array(dataSet)\n",
    "\n",
    "        #除了最后一列不取，前面列数全取\n",
    "        trainData = dataSetNP[:,0:dataSetNP.shape[1]-1]\n",
    "\n",
    "        #没有冒号表示取当前列，也就是最后一列\n",
    "        labels = dataSetNP[:,dataSetNP.shape[1]-1]\n",
    "        return trainData,labels\n",
    "    \n",
    "    #求labels 中的每个label的先验概率\n",
    "    def classify(self,trainData,labels,features):\n",
    "        \n",
    "        \n",
    "        labels =list(labels)\n",
    "        probability_y={}#概率集合\n",
    "        \n",
    "\n",
    "        Latex('''  $p(A)$  ：事件A发生的概率  ''')\n",
    "        #每一个标签数量除以总数\n",
    "        for label in labels:\n",
    "            probability_y[label] = labels.count(label)/float(len(labels))\n",
    "\n",
    "        Latex('''  $p(A\\cap\\;B)$  ：事件A 和事件B同时发生的概率   ''')\n",
    "        #求label与feature同时发生的概率\n",
    "        probability_xy={}\n",
    "        for y in probability_y.keys():\n",
    "            #labels 放入枚举函数中，形成（序号，值）这一数据结构\n",
    "            y_index = [i for i,label in enumerate(labels) if label == y]\n",
    "            #y_index 对应标签的一行值 的 所有位置\n",
    "\n",
    "            for j in range(len(features)):\n",
    "                x_index = [i for i,feature in enumerate(trainData[:,j]) if feature == features[j]]\n",
    "                #set 是集合，& 交集，| 并集，- 差集 ，in 属于,not in 不属于\n",
    "                #求 x_index 和 y_index的 两个集合的交集。也就是同时发生的次数\n",
    "                xy_count = len(set(x_index)&set(y_index))\n",
    "                \n",
    "\n",
    "                probaility_key = str(features[j])+'*'+str(y)\n",
    "                print(probaility_key)\n",
    "                probability_xy[probaility_key] = xy_count/float(len(labels))\n",
    "\n",
    "        #条件概率\n",
    "        Latex('''  $p(A|B)$  ：表示事件A在事件B发生的条件下发生的概率  ''')\n",
    "         #P[X1/Y] = P[X1Y]/P[Y]\n",
    "        Latex(''' $P[X|Y] = P[X\\cap\\;Y]/P[Y] $''')\n",
    "        probability={}\n",
    "        for y in probability_y.keys():\n",
    "            for x in features:\n",
    "                pkey = str(x)+'|'+str(y)\n",
    "\n",
    "                \n",
    "                probability[pkey] = probability_xy[str(x)+'*'+str(y)]/float(probability_y[y])\n",
    "        \n",
    "\n",
    "        #求各个类别的概率\n",
    "        Class_each={}\n",
    "        for y in probability_y:\n",
    "            Class_each[y]=probability_y[y]\n",
    "            for x in features:\n",
    "                print(Class_each[y])\n",
    "                print(probability[str(x)+'|'+str(y)])\n",
    "                Class_each[y] =Class_each[y]*probability[str(x)+'|'+str(y)]\n",
    "\n",
    "        features_label =max(Class_each,key=Class_each.get)\n",
    "        return features_label\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    nb=NaiveBayes()\n",
    "    #训练数据\n",
    "    trainData,labels = nb.getTrainSet()\n",
    "    #x1,x2\n",
    "    features = [2,'S']\n",
    "    #该特征应属于哪一类\n",
    "    result = nb.classify(trainData,labels,features)\n",
    "    print(features)\n",
    "    print('属于')\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[10 15 20 25]\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n",
      "切片\n",
      "[14 34 54 74]\n"
     ]
    }
   ],
   "source": [
    "a3 = np.empty((2,3))\n",
    "print(a3)\n",
    "a4 = np.arange(10,30,5)\n",
    "print(a4)\n",
    "c = np.arange(100).reshape(10,10)\n",
    "print(c)\n",
    "print(\"切片\")\n",
    "print(c[1:8:2,4])#逗号前表示1:3  表示取哪几行以及步长。 逗号后表示取哪几列以及步长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\sum_{i=0}^{n}i^2 $\n",
    "$$ \\boxed{E=mc^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sum_{i=0}^{n}i^2 $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\boxed{E=mc^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-53b705adb77e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNaiveBayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#训练数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrainSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m#x1,x2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'S'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-8612c933c62b>\u001b[0m in \u001b[0;36mgetTrainSet\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#返回数据表和标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetTrainSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mdataSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'naivebayes_data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mdataSetNP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Latex\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nb=NaiveBayes()\n",
    "    #训练数据\n",
    "    trainData,labels = nb.getTrainSet()\n",
    "    #x1,x2\n",
    "    features = [2,'S']\n",
    "    #该特征应属于哪一类\n",
    "    result = nb.classify(trainData,labels,features)\n",
    "    print(features)\n",
    "    print('属于')\n",
    "    print(result)\n",
    "\n",
    "class NaiveBayes(object):\n",
    "    #返回数据表和标签\n",
    "    def getTrainSet(self):\n",
    "        dataSet = pd.read_csv('naivebayes_data.csv')\n",
    "        dataSetNP = np.array(dataSet)\n",
    "\n",
    "        #除了最后一列不取，前面列数全取\n",
    "        trainData = dataSet[:,0:dataSetNP.shape[1]-1]\n",
    "\n",
    "        #没有冒号表示取当前列，也就是最后一列\n",
    "        labels = dataSetNP[:,dataSetNP.shape[1]-1]\n",
    "        return trainData,labels\n",
    "    \n",
    "    #求labels 中的每个label的先验概率\n",
    "    def classify(self,trainData,labels,features):\n",
    "        \n",
    "        \n",
    "        labels =list(labels)\n",
    "        probability_y={}#概率集合\n",
    "        \n",
    "\n",
    "        Latex('''  $p(A)$  ：事件A发生的概率  ''')\n",
    "        #每一个标签数量除以总数\n",
    "        for label in labels:\n",
    "            probability_y[label] = labels.count(label)/float(len(labels))\n",
    "\n",
    "        Latex('''  $p(A\\cap\\;B)$  ：事件A 和事件B同时发生的概率   ''')\n",
    "        #求label与feature同时发生的概率\n",
    "        probability_xy={}\n",
    "        for y in probability_y.keys():\n",
    "            #labels 放入枚举函数中，形成（序号，值）这一数据结构\n",
    "            y_index = [i for i,label in enumerate(labels) if label == y]\n",
    "            #y_index 对应标签的一行值 的 所有位置\n",
    "\n",
    "            for j in range(len(features)):\n",
    "                x_index = [i for i,feature in enumerate(trainData[:,j]) if feature == features[j]]\n",
    "                #set 是集合，& 交集，| 并集，- 差集 ，in 属于,not in 不属于\n",
    "                #求 x_index 和 y_index的 两个集合的交集。也就是同时发生的次数\n",
    "                xy_count = len(set(x_index)&set(y_index))\n",
    "                \n",
    "\n",
    "                probaility_key = str(features[j])+'*'+str(y)\n",
    "                print(probaility_key)\n",
    "                probability_xy[probaility_key] = xy_count/float(len(labels))\n",
    "\n",
    "        #条件概率\n",
    "        Latex('''  $p(A|B)$  ：表示事件A在事件B发生的条件下发生的概率  ''')\n",
    "         #P[X1/Y] = P[X1Y]/P[Y]\n",
    "        Latex(''' $P[X|Y] = P[X\\cap\\;Y]/P[Y] $''')\n",
    "        probability={}\n",
    "        for y in probability_y.keys():\n",
    "            for x in features:\n",
    "                pkey = str(x)+'|'+str(y)\n",
    "\n",
    "                \n",
    "                probability = probability_xy[str(x)+'*'+str(y)]/float(probability_y[y])\n",
    "        \n",
    "\n",
    "        #求各个类别的概率\n",
    "        Class_each={}\n",
    "        for y in probability_y:\n",
    "            Class_each[y]=probability_y[y]\n",
    "            for x in features:\n",
    "                Class_each[y] =Class_each[y]*probability[str(x)+'|'+str(y)]\n",
    "\n",
    "        features_label =max(Class_each,key=Class_each.get)\n",
    "        return features_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
